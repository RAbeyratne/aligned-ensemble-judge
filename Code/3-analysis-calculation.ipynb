{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6a9382-1d0f-442b-b8c1-dff14d593012",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install transformers\n",
    "!pip install torch\n",
    "!pip install datasets\n",
    "!pip install transformers accelerate bitsandbytes\n",
    "!pip install nltk\n",
    "!pip install tqdm\n",
    "!pip install rank-bm25 rouge-score nltk\n",
    "\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from collections import defaultdict, Counter\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from datasets import Dataset, DatasetDict, load_dataset\n",
    "from huggingface_hub import login\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, BertTokenizer, BertModel, AutoTokenizer, AutoModel\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from rank_bm25 import BM25Okapi\n",
    "from rouge_score import rouge_scorer\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import re\n",
    "import seaborn as sns\n",
    "import transformers\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69e81ee-d229-47d7-bdcd-cc2bfbeeef92",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "HF_L = \"XXX\"\n",
    "login(token=HF_L)\n",
    "\n",
    "model = 'llama'\n",
    "\n",
    "if model == 'llama':\n",
    "    llama_model_name = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "    llama_tokenizer = AutoTokenizer.from_pretrained(llama_model_name, use_auth_token=HF_L)\n",
    "    llama_model = AutoModelForCausalLM.from_pretrained(\n",
    "        llama_model_name,\n",
    "        torch_dtype=torch.float16,\n",
    "        device_map=\"auto\",\n",
    "        use_auth_token=HF_L\n",
    "    )\n",
    "if model == 'falcon':\n",
    "    falcon_model_name = \"tiiuae/falcon-7b-instruct\"\n",
    "    falcon_model = AutoModelForCausalLM.from_pretrained(\n",
    "        falcon_model_name,\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        trust_remote_code=True,\n",
    "        device_map=\"auto\",\n",
    "    )\n",
    "    falcon_tokenizer = AutoTokenizer.from_pretrained(falcon_model_name)\n",
    "    falcon_pipeline = transformers.pipeline(\n",
    "        \"text-generation\",\n",
    "        model=falcon_model,\n",
    "        tokenizer=falcon_tokenizer,\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        trust_remote_code=True,\n",
    "        device_map=\"auto\",\n",
    "    )\n",
    "if model == 'gemma':\n",
    "    gemma_tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-7b-it\")\n",
    "    gemma_model = AutoModelForCausalLM.from_pretrained(\n",
    "        \"google/gemma-7b-it\", \n",
    "        device_map=\"auto\", \n",
    "        revision=\"float16\")\n",
    "if model == 'mistral':\n",
    "    device = \"cuda\"\n",
    "    mistral_model = AutoModelForCausalLM.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\")\n",
    "    mistral_tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acac042a-57a9-4ca3-a515-7523d4b34ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_llama_embeddings(prompt, seed=42):\n",
    "    inputs = llama_tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "    torch.manual_seed(seed)    \n",
    "    llama_model.config.output_hidden_states = True    \n",
    "    with torch.no_grad():\n",
    "        outputs = llama_model(**inputs)    \n",
    "    embeddings = outputs.hidden_states[-1]\n",
    "    attention_mask = inputs[\"attention_mask\"].unsqueeze(-1)\n",
    "    embeddings = embeddings * attention_mask\n",
    "    sum_embeddings = embeddings.sum(dim=1)\n",
    "    mask_sum = attention_mask.sum(dim=1)\n",
    "    mean_pooled = sum_embeddings / mask_sum\n",
    "    mean_pooled = mean_pooled.float().detach().cpu().numpy()\n",
    "    return mean_pooled[0]\n",
    "    \n",
    "def get_falcon_embeddings(prompt, seed=42):\n",
    "    if not hasattr(falcon_model, \"config\"):\n",
    "        raise ValueError(\"falcon_model is not properly initialized. Please load the model correctly.\")\n",
    "    inputs = falcon_tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "    torch.manual_seed(seed)\n",
    "    falcon_model.config.output_hidden_states = True\n",
    "    with torch.no_grad():\n",
    "        outputs = falcon_model(**inputs)\n",
    "    embeddings = outputs.hidden_states[-1]\n",
    "    embeddings = outputs.hidden_states[-1]\n",
    "    attention_mask = inputs[\"attention_mask\"].unsqueeze(-1)\n",
    "    embeddings = embeddings * attention_mask\n",
    "    sum_embeddings = embeddings.sum(dim=1)\n",
    "    mask_sum = attention_mask.sum(dim=1)\n",
    "    mean_pooled = sum_embeddings / mask_sum\n",
    "    mean_pooled = mean_pooled.float().detach().cpu().numpy()\n",
    "    return mean_pooled[0]\n",
    "    \n",
    "def get_gemma_embeddings(prompt, seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"    \n",
    "    gemma_model.to(device)    \n",
    "    inputs = gemma_tokenizer(prompt, return_tensors=\"pt\")  \n",
    "    input_ids = inputs[\"input_ids\"].to(device)    \n",
    "    attention_mask = inputs[\"attention_mask\"].to(device)\n",
    "    gemma_model.config.output_hidden_states = True\n",
    "    with torch.no_grad():\n",
    "        outputs = gemma_model(input_ids=input_ids) \n",
    "    embeddings = outputs.hidden_states[-1]\n",
    "    attention_mask = attention_mask.unsqueeze(-1)\n",
    "    embeddings = embeddings * attention_mask    \n",
    "    sum_embeddings = embeddings.sum(dim=1)\n",
    "    mask_sum = attention_mask.sum(dim=1)    \n",
    "    mean_pooled = sum_embeddings / mask_sum\n",
    "    mean_pooled = mean_pooled.float().detach().cpu().numpy()    \n",
    "    return mean_pooled[0]\n",
    "    \n",
    "def get_mistral_embeddings(prompt, seed=42):\n",
    "    global mistral_model\n",
    "    mistral_model = mistral_model.to(\"cuda\")    \n",
    "    inputs = mistral_tokenizer(prompt, return_tensors=\"pt\")\n",
    "    inputs = {key: value.to(\"cuda\") for key, value in inputs.items()}    \n",
    "    torch.manual_seed(seed)\n",
    "    mistral_model.config.output_hidden_states = True    \n",
    "    with torch.no_grad():\n",
    "        outputs = mistral_model(**inputs)    \n",
    "    embeddings = outputs.hidden_states[-1]\n",
    "    attention_mask = inputs[\"attention_mask\"].unsqueeze(-1)\n",
    "    embeddings = embeddings * attention_mask\n",
    "    sum_embeddings = embeddings.sum(dim=1)\n",
    "    mask_sum = attention_mask.sum(dim=1)\n",
    "    mean_pooled = sum_embeddings / mask_sum\n",
    "    mean_pooled = mean_pooled.float().detach().cpu().numpy()\n",
    "    return mean_pooled[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3752b394-a98e-4623-b38c-52a57c8dfbed",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_cosine_similarity(emb1, emb2):\n",
    "    emb1 = emb1.reshape(1, -1) if emb1.ndim == 1 else emb1\n",
    "    emb2 = emb2.reshape(1, -1) if emb2.ndim == 1 else emb2\n",
    "    similarity = cosine_similarity(emb1, emb2)\n",
    "    return similarity[0, 0]\n",
    "\n",
    "def get_case_alignment(case_embs, case_base):\n",
    "    emb1, emb2 = case_embs\n",
    "    emb1 = emb1.reshape(1, -1) if emb1.ndim == 1 else emb1\n",
    "    emb2 = emb2.reshape(1, -1) if emb2.ndim == 1 else emb2\n",
    "    alignment_scores = []\n",
    "    for past_case in case_base:\n",
    "        past_prob_emb, past_solution_emb = past_case\n",
    "        past_prob_emb = past_prob_emb.reshape(1, -1) if past_prob_emb.ndim == 1 else past_prob_emb\n",
    "        past_solution_emb = past_solution_emb.reshape(1, -1) if past_solution_emb.ndim == 1 else past_solution_emb\n",
    "        prob_similarity = cosine_similarity(emb1, past_prob_emb)\n",
    "        solution_similarity = cosine_similarity(emb2, past_solution_emb)\n",
    "        alignment_score = (prob_similarity + solution_similarity) / 2.0\n",
    "        alignment_scores.append(alignment_score)\n",
    "    return (sum(alignment_scores) / len(alignment_scores))[0][0]\n",
    "\n",
    "def get_weighted_case_alignment(case_embs, case_base):\n",
    "    emb1, emb2 = case_embs\n",
    "    emb1 = emb1.reshape(1, -1) if emb1.ndim == 1 else emb1\n",
    "    emb2 = emb2.reshape(1, -1) if emb2.ndim == 1 else emb2\n",
    "\n",
    "    alignment_scores = []\n",
    "    weights = []\n",
    "    for past_case in case_base:\n",
    "        past_prob_emb, past_solution_emb = past_case\n",
    "        past_prob_emb = past_prob_emb.reshape(1, -1) if past_prob_emb.ndim == 1 else past_prob_emb\n",
    "        past_solution_emb = past_solution_emb.reshape(1, -1) if past_solution_emb.ndim == 1 else past_solution_emb\n",
    "        prob_similarity = cosine_similarity(emb1, past_prob_emb)[0][0]\n",
    "        solution_similarity = cosine_similarity(emb2, past_solution_emb)[0][0]\n",
    "        alignment_score = (prob_similarity + solution_similarity) / 2.0\n",
    "        alignment_scores.append(alignment_score)\n",
    "        weights.append(prob_similarity)\n",
    "    total_weight = sum(weights)\n",
    "    if total_weight == 0:\n",
    "        return 0\n",
    "    normalized_weights = [w / total_weight for w in weights]\n",
    "    weighted_alignment_score = sum(a * w for a, w in zip(alignment_scores, normalized_weights))\n",
    "    return weighted_alignment_score\n",
    "\n",
    "def get_question_alignment(case_embs, case_base):\n",
    "    emb1, _ = case_embs\n",
    "    emb1 = emb1.reshape(1, -1) if emb1.ndim == 1 else emb1\n",
    "    alignment_scores = []    \n",
    "    for past_case in case_base:\n",
    "        past_prob_emb, _ = past_case\n",
    "        past_prob_emb = past_prob_emb.reshape(1, -1) if past_prob_emb.ndim == 1 else past_prob_emb\n",
    "        prob_similarity = cosine_similarity(emb1, past_prob_emb)\n",
    "        alignment_scores.append(prob_similarity)    \n",
    "    return (sum(alignment_scores) / len(alignment_scores))[0][0]\n",
    "\n",
    "def calculate_iaa_scores(cosine_scores_rounded, external_cosine_score_rounded):\n",
    "    cosine_scores = np.array(cosine_scores_rounded)\n",
    "    bins = np.arange(0, 1.1, 0.1)\n",
    "\n",
    "    def bin_scores(scores, bins):\n",
    "        return np.digitize(scores, bins) - 1\n",
    "\n",
    "    binned_scores = [bin_scores(scores, bins) for scores in cosine_scores]\n",
    "    pairwise_similarities = []\n",
    "    for i in range(len(binned_scores)):\n",
    "        for j in range(i + 1, len(binned_scores)):\n",
    "            similarity = np.mean(np.array(binned_scores[i]) == np.array(binned_scores[j]))\n",
    "            pairwise_similarities.append(similarity)\n",
    "    mean_iaa = np.mean(pairwise_similarities)\n",
    "    external_binned_score = bin_scores([external_cosine_score_rounded], bins)[0]\n",
    "    total_agreement = 0\n",
    "    total_disagreement = 0\n",
    "    for binned_score in binned_scores:\n",
    "        total_agreement += np.sum(np.array(binned_score) == external_binned_score)\n",
    "        total_disagreement += np.sum(np.array(binned_score) != external_binned_score)\n",
    "    return mean_iaa, total_agreement / len(cosine_scores_rounded), total_disagreement / len(cosine_scores_rounded)\n",
    "\n",
    "def calculate_bm25(text1, text2):\n",
    "    corpus = [text1.split(), text2.split()]\n",
    "    bm25 = BM25Okapi(corpus)\n",
    "    query = text1.split()\n",
    "    scores = bm25.get_scores(query)\n",
    "    score = scores[1]\n",
    "    max_score = max(scores) if len(scores) > 0 else 1.0\n",
    "    return score / max_score\n",
    "\n",
    "def calculate_rouge(text1, text2):\n",
    "    scorer = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n",
    "    scores = scorer.score(text1, text2)\n",
    "    rouge_l_score = scores['rougeL'].fmeasure\n",
    "    return rouge_l_score\n",
    "\n",
    "def calculate_bleu(text1, text2):\n",
    "    reference = [word_tokenize(text1)]\n",
    "    candidate = word_tokenize(text2)\n",
    "    smoothing_function = SmoothingFunction().method1\n",
    "    score = sentence_bleu(reference, candidate, smoothing_function=smoothing_function)\n",
    "    return max(0.0, min(1.0, score))\n",
    "\n",
    "def calculate_bm25_rouge_bleu(gold_standard, text1, text2, text3):\n",
    "    bm25_score = (calculate_bm25(gold_standard, text1) + calculate_bm25(gold_standard, text2) + calculate_bm25(gold_standard, text3) / 3)\n",
    "    rouge_score = (calculate_rouge(gold_standard, text1) + calculate_rouge(gold_standard, text2) + calculate_rouge(gold_standard, text3) / 3)\n",
    "    bleu_score = (calculate_bleu(gold_standard, text1) + calculate_bleu(gold_standard, text2) + calculate_bleu(gold_standard, text3) / 3)\n",
    "    return bm25_score, rouge_score, bleu_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7dc581-173d-4d7f-853d-1345f8eb06d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['llama', 'falcon', 'gemma', 'mistral']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15de85fc",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for mod in models:\n",
    "    if mod != model:\n",
    "        continue;\n",
    "    print(mod)\n",
    "    dataset = load_dataset(\"Ramitha/alqa-results-40-\" + mod)\n",
    "    df = pd.DataFrame(dataset['rawcases'])\n",
    "    for index, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing Rows\"):\n",
    "        if mod == 'llama':\n",
    "            question_emb = json.dumps(get_llama_embeddings(df.at[index, 'question']).tolist())\n",
    "            snippet_emb = json.dumps(get_llama_embeddings(df.at[index, 'snippet']).tolist())\n",
    "            answer_emb = json.dumps(get_llama_embeddings(df.at[index, 'answer']).tolist())\n",
    "            answerGenerated_emb = json.dumps(get_llama_embeddings(df.at[index, 'answerGenerated']).tolist())\n",
    "            question_answerGenerated_falcon_emb = json.dumps(get_llama_embeddings(df.at[index, 'question_answerGenerated_falcon']).tolist())\n",
    "            question_answerGenerated_gemma_emb = json.dumps(get_llama_embeddings(df.at[index, 'question_answerGenerated_gemma']).tolist())\n",
    "            question_answerGenerated_mistral_emb = json.dumps(get_llama_embeddings(df.at[index, 'question_answerGenerated_mistral']).tolist())\n",
    "            reverse_answer_answerGenerated_gemma_emb = json.dumps(get_llama_embeddings(df.at[index, 'reverse_answer_answerGenerated_gemma']).tolist())\n",
    "            reverse_answer_answerGenerated_falcon_emb = json.dumps(get_llama_embeddings(df.at[index, 'reverse_answer_answerGenerated_falcon']).tolist())\n",
    "            reverse_answer_answerGenerated_mistral_emb = json.dumps(get_llama_embeddings(df.at[index, 'reverse_answer_answerGenerated_mistral']).tolist())\n",
    "            judge_answer_answerGenerated_gemma_emb = json.dumps(get_llama_embeddings(df.at[index, 'judge_answer_answerGenerated_gemma']).tolist())\n",
    "            judge_answer_answerGenerated_falcon_emb = json.dumps(get_llama_embeddings(df.at[index, 'judge_answer_answerGenerated_falcon']).tolist())\n",
    "            judge_answer_answerGenerated_mistral_emb = json.dumps(get_llama_embeddings(df.at[index, 'judge_answer_answerGenerated_mistral']).tolist())            \n",
    "            df.at[index, 'question_emb'] = question_emb\n",
    "            df.at[index, 'snippet_emb'] = snippet_emb\n",
    "            df.at[index, 'answer_emb'] = answer_emb\n",
    "            df.at[index, 'answerGenerated_emb'] = answerGenerated_emb\n",
    "            df.at[index, 'question_answerGenerated_falcon_emb'] = question_answerGenerated_falcon_emb\n",
    "            df.at[index, 'question_answerGenerated_gemma_emb'] = question_answerGenerated_gemma_emb\n",
    "            df.at[index, 'question_answerGenerated_mistral_emb'] = question_answerGenerated_mistral_emb\n",
    "            df.at[index, 'reverse_answer_answerGenerated_gemma_emb'] = reverse_answer_answerGenerated_gemma_emb\n",
    "            df.at[index, 'reverse_answer_answerGenerated_falcon_emb'] = reverse_answer_answerGenerated_falcon_emb\n",
    "            df.at[index, 'reverse_answer_answerGenerated_mistral_emb'] = reverse_answer_answerGenerated_mistral_emb\n",
    "            df.at[index, 'judge_answer_answerGenerated_gemma_emb'] = judge_answer_answerGenerated_gemma_emb\n",
    "            df.at[index, 'judge_answer_answerGenerated_falcon_emb'] = judge_answer_answerGenerated_falcon_emb\n",
    "            df.at[index, 'judge_answer_answerGenerated_mistral_emb'] = judge_answer_answerGenerated_mistral_emb            \n",
    "            df.at[index, 'gold_standard_cos'] = get_cosine_similarity(np.array(json.loads(answer_emb)), np.array(json.loads(answerGenerated_emb)))    \n",
    "            # Cosine\n",
    "            df.at[index, 'question_answerGenerated_falcon_cos']  = get_cosine_similarity(np.array(json.loads(question_emb)), np.array(json.loads(question_answerGenerated_falcon_emb)))\n",
    "            df.at[index, 'question_answerGenerated_gemma_cos']  = get_cosine_similarity(np.array(json.loads(question_emb)), np.array(json.loads(question_answerGenerated_gemma_emb)))\n",
    "            df.at[index, 'question_answerGenerated_mistral_cos']  = get_cosine_similarity(np.array(json.loads(question_emb)), np.array(json.loads(question_answerGenerated_mistral_emb)))\n",
    "            df.at[index, 'judge_answer_answerGenerated_falcon_cos']  = get_cosine_similarity(np.array(json.loads(answer_emb)), np.array(json.loads(judge_answer_answerGenerated_falcon_emb)))\n",
    "            df.at[index, 'judge_answer_answerGenerated_gemma_cos']  = get_cosine_similarity(np.array(json.loads(answer_emb)), np.array(json.loads(judge_answer_answerGenerated_gemma_emb)))\n",
    "            df.at[index, 'judge_answer_answerGenerated_mistral_cos']  = get_cosine_similarity(np.array(json.loads(answer_emb)), np.array(json.loads(judge_answer_answerGenerated_mistral_emb)))\n",
    "            df.at[index, 'ILRSim']  = np.mean([\n",
    "                df.at[index, 'question_answerGenerated_falcon_cos'],\n",
    "                df.at[index, 'question_answerGenerated_gemma_cos'],\n",
    "                df.at[index, 'question_answerGenerated_mistral_cos']\n",
    "            ])                        \n",
    "            df.at[index, 'answer_judge_cos_mean']  = np.mean([\n",
    "                df.at[index, 'judge_answer_answerGenerated_falcon_cos'],\n",
    "                df.at[index, 'judge_answer_answerGenerated_gemma_cos'],\n",
    "                df.at[index, 'judge_answer_answerGenerated_mistral_cos']\n",
    "            ])\n",
    "            df.at[index, 'question_snippet_similarity'] = get_cosine_similarity(np.array(json.loads(question_emb)), np.array(json.loads(snippet_emb)))\n",
    "            # Iaa\n",
    "            df.at[index, 'iaa_fleiss_kappa'], df.at[index, 'iaa_fleiss_kappa_agreement'], df.at[index, 'iaa_fleiss_kappa_disagreement'] = calculate_iaa_scores([\n",
    "                [round(df.at[index, 'question_answerGenerated_falcon_cos'], 2)],\n",
    "                [round(df.at[index, 'question_answerGenerated_gemma_cos'], 2)],\n",
    "                [round(df.at[index, 'question_answerGenerated_mistral_cos'], 2)]\n",
    "            ], round(df.at[index, 'gold_standard_cos'], 2))\n",
    "            # Reconstruction error\n",
    "            df.at[index, 'question_reconstruction_falcon_error'] = np.mean((\n",
    "                np.array(json.loads(question_emb)) - np.array(json.loads(question_answerGenerated_falcon_emb))\n",
    "            ) ** 2)\n",
    "            df.at[index, 'question_reconstruction_gemma_error'] = np.mean((\n",
    "                np.array(json.loads(question_emb)) - np.array(json.loads(question_answerGenerated_gemma_emb))\n",
    "            ) ** 2)\n",
    "            df.at[index, 'question_reconstruction_mistral_error'] = np.mean((\n",
    "                np.array(json.loads(question_emb)) - np.array(json.loads(question_answerGenerated_mistral_emb))\n",
    "            ) ** 2)\n",
    "            df.at[index, 'ILRError']  = np.mean([\n",
    "                df.at[index, 'question_reconstruction_falcon_error'],\n",
    "                df.at[index, 'question_reconstruction_gemma_error'],\n",
    "                df.at[index, 'question_reconstruction_mistral_error']\n",
    "            ])\n",
    "            # Case alignment\n",
    "            case_ = [np.array(json.loads(question_emb)), np.array(json.loads(answerGenerated_emb))]\n",
    "            case_base = [\n",
    "                [np.array(json.loads(question_answerGenerated_falcon_emb)), np.array(json.loads(reverse_answer_answerGenerated_falcon_emb))],\n",
    "                [np.array(json.loads(question_answerGenerated_gemma_emb)), np.array(json.loads(reverse_answer_answerGenerated_gemma_emb))],\n",
    "                [np.array(json.loads(question_answerGenerated_mistral_emb)), np.array(json.loads(reverse_answer_answerGenerated_mistral_emb))]\n",
    "            ]\n",
    "            df.at[index, 'ILRAlign'] = get_case_alignment(case_, case_base)\n",
    "            df.at[index, 'WILRAlign'] = get_weighted_case_alignment(case_, case_base)\n",
    "            df.at[index, 'question_alignment'] = get_question_alignment(case_, case_base)\n",
    "            df.at[index, 'question_bm25_score_mean'], df.at[index, 'question_rouge_score_mean'], df.at[index, 'question_bleu_score_mean'] = calculate_bm25_rouge_bleu(\n",
    "                df.at[index, 'question'], df.at[index, 'question_answerGenerated_gemma'] , df.at[index, 'question_answerGenerated_falcon'], df.at[index, 'question_answerGenerated_mistral'])\n",
    "        if mod == 'falcon':\n",
    "            question_emb = json.dumps(get_falcon_embeddings(df.at[index, 'question']).tolist())\n",
    "            snippet_emb = json.dumps(get_falcon_embeddings(df.at[index, 'snippet']).tolist())\n",
    "            answer_emb = json.dumps(get_falcon_embeddings(df.at[index, 'answer']).tolist())\n",
    "            answerGenerated_emb = json.dumps(get_falcon_embeddings(df.at[index, 'answerGenerated']).tolist())\n",
    "            question_answerGenerated_llama_emb = json.dumps(get_falcon_embeddings(df.at[index, 'question_answerGenerated_llama']).tolist())\n",
    "            question_answerGenerated_gemma_emb = json.dumps(get_falcon_embeddings(df.at[index, 'question_answerGenerated_gemma']).tolist())\n",
    "            question_answerGenerated_mistral_emb = json.dumps(get_falcon_embeddings(df.at[index, 'question_answerGenerated_mistral']).tolist())\n",
    "            reverse_answer_answerGenerated_gemma_emb = json.dumps(get_falcon_embeddings(df.at[index, 'reverse_answer_answerGenerated_gemma']).tolist())\n",
    "            reverse_answer_answerGenerated_llama_emb = json.dumps(get_falcon_embeddings(df.at[index, 'reverse_answer_answerGenerated_llama']).tolist())\n",
    "            reverse_answer_answerGenerated_mistral_emb = json.dumps(get_falcon_embeddings(df.at[index, 'reverse_answer_answerGenerated_mistral']).tolist())\n",
    "            judge_answer_answerGenerated_gemma_emb = json.dumps(get_falcon_embeddings(df.at[index, 'judge_answer_answerGenerated_gemma']).tolist())\n",
    "            judge_answer_answerGenerated_llama_emb = json.dumps(get_falcon_embeddings(df.at[index, 'judge_answer_answerGenerated_llama']).tolist())\n",
    "            judge_answer_answerGenerated_mistral_emb = json.dumps(get_falcon_embeddings(df.at[index, 'judge_answer_answerGenerated_mistral']).tolist())            \n",
    "            df.at[index, 'question_emb'] = question_emb\n",
    "            df.at[index, 'snippet_emb'] = snippet_emb\n",
    "            df.at[index, 'answer_emb'] = answer_emb\n",
    "            df.at[index, 'answerGenerated_emb'] = answerGenerated_emb\n",
    "            df.at[index, 'question_answerGenerated_llama_emb'] = question_answerGenerated_llama_emb\n",
    "            df.at[index, 'question_answerGenerated_gemma_emb'] = question_answerGenerated_gemma_emb\n",
    "            df.at[index, 'question_answerGenerated_mistral_emb'] = question_answerGenerated_mistral_emb\n",
    "            df.at[index, 'reverse_answer_answerGenerated_gemma_emb'] = reverse_answer_answerGenerated_gemma_emb\n",
    "            df.at[index, 'reverse_answer_answerGenerated_llama_emb'] = reverse_answer_answerGenerated_llama_emb\n",
    "            df.at[index, 'reverse_answer_answerGenerated_mistral_emb'] = reverse_answer_answerGenerated_mistral_emb\n",
    "            df.at[index, 'judge_answer_answerGenerated_gemma_emb'] = judge_answer_answerGenerated_gemma_emb\n",
    "            df.at[index, 'judge_answer_answerGenerated_llama_emb'] = judge_answer_answerGenerated_llama_emb\n",
    "            df.at[index, 'judge_answer_answerGenerated_mistral_emb'] = judge_answer_answerGenerated_mistral_emb            \n",
    "            df.at[index, 'gold_standard_cos'] = get_cosine_similarity(np.array(json.loads(answer_emb)), np.array(json.loads(answerGenerated_emb)))\n",
    "            # Cosine\n",
    "            df.at[index, 'question_answerGenerated_llama_cos']  = get_cosine_similarity(np.array(json.loads(question_emb)), np.array(json.loads(question_answerGenerated_llama_emb)))\n",
    "            df.at[index, 'question_answerGenerated_gemma_cos']  = get_cosine_similarity(np.array(json.loads(question_emb)), np.array(json.loads(question_answerGenerated_gemma_emb)))\n",
    "            df.at[index, 'question_answerGenerated_mistral_cos']  = get_cosine_similarity(np.array(json.loads(question_emb)), np.array(json.loads(question_answerGenerated_mistral_emb)))\n",
    "            df.at[index, 'judge_answer_answerGenerated_llama_cos']  = get_cosine_similarity(np.array(json.loads(answer_emb)), np.array(json.loads(judge_answer_answerGenerated_llama_emb)))\n",
    "            df.at[index, 'judge_answer_answerGenerated_gemma_cos']  = get_cosine_similarity(np.array(json.loads(answer_emb)), np.array(json.loads(judge_answer_answerGenerated_gemma_emb)))\n",
    "            df.at[index, 'judge_answer_answerGenerated_mistral_cos']  = get_cosine_similarity(np.array(json.loads(answer_emb)), np.array(json.loads(judge_answer_answerGenerated_mistral_emb)))\n",
    "            df.at[index, 'ILRSim']  = np.mean([\n",
    "                df.at[index, 'question_answerGenerated_llama_cos'],\n",
    "                df.at[index, 'question_answerGenerated_gemma_cos'],\n",
    "                df.at[index, 'question_answerGenerated_mistral_cos']\n",
    "            ])\n",
    "            df.at[index, 'answer_judge_cos_mean']  = np.mean([\n",
    "                df.at[index, 'judge_answer_answerGenerated_llama_cos'],\n",
    "                df.at[index, 'judge_answer_answerGenerated_gemma_cos'],\n",
    "                df.at[index, 'judge_answer_answerGenerated_mistral_cos']\n",
    "            ])\n",
    "            df.at[index, 'question_snippet_similarity'] = get_cosine_similarity(np.array(json.loads(question_emb)), np.array(json.loads(snippet_emb)))\n",
    "            # Iaa\n",
    "            df.at[index, 'iaa_fleiss_kappa'], df.at[index, 'iaa_fleiss_kappa_agreement'], df.at[index, 'iaa_fleiss_kappa_disagreement'] = calculate_iaa_scores([\n",
    "                [round(df.at[index, 'question_answerGenerated_llama_cos'], 2)],\n",
    "                [round(df.at[index, 'question_answerGenerated_gemma_cos'], 2)],\n",
    "                [round(df.at[index, 'question_answerGenerated_mistral_cos'], 2)]\n",
    "            ], round(df.at[index, 'gold_standard_cos'], 2))\n",
    "            # Reconstruction error\n",
    "            df.at[index, 'question_reconstruction_llama_error'] = np.mean((\n",
    "                np.array(json.loads(question_emb)) - np.array(json.loads(question_answerGenerated_llama_emb))\n",
    "            ) ** 2)\n",
    "            df.at[index, 'question_reconstruction_gemma_error'] = np.mean((\n",
    "                np.array(json.loads(question_emb)) - np.array(json.loads(question_answerGenerated_gemma_emb))\n",
    "            ) ** 2)\n",
    "            df.at[index, 'question_reconstruction_mistral_error'] = np.mean((\n",
    "                np.array(json.loads(question_emb)) - np.array(json.loads(question_answerGenerated_mistral_emb))\n",
    "            ) ** 2)\n",
    "            df.at[index, 'ILRError']  = np.mean([\n",
    "                df.at[index, 'question_reconstruction_llama_error'],\n",
    "                df.at[index, 'question_reconstruction_gemma_error'],\n",
    "                df.at[index, 'question_reconstruction_mistral_error']\n",
    "            ])\n",
    "            # Case alignment\n",
    "            case_ = [np.array(json.loads(question_emb)), np.array(json.loads(answerGenerated_emb))]\n",
    "            case_base = [\n",
    "                [np.array(json.loads(question_answerGenerated_llama_emb)), np.array(json.loads(reverse_answer_answerGenerated_llama_emb))],\n",
    "                [np.array(json.loads(question_answerGenerated_gemma_emb)), np.array(json.loads(reverse_answer_answerGenerated_gemma_emb))],\n",
    "                [np.array(json.loads(question_answerGenerated_mistral_emb)), np.array(json.loads(reverse_answer_answerGenerated_mistral_emb))]\n",
    "            ]\n",
    "            df.at[index, 'ILRAlign'] = get_case_alignment(case_, case_base)\n",
    "            df.at[index, 'WILRAlign'] = get_weighted_case_alignment(case_, case_base)\n",
    "            df.at[index, 'question_alignment'] = get_question_alignment(case_, case_base)\n",
    "            df.at[index, 'question_bm25_score_mean'], df.at[index, 'question_rouge_score_mean'], df.at[index, 'question_bleu_score_mean'] = calculate_bm25_rouge_bleu(\n",
    "                df.at[index, 'question'], df.at[index, 'question_answerGenerated_gemma'] , df.at[index, 'question_answerGenerated_mistral'], df.at[index, 'question_answerGenerated_llama'])\n",
    "        if mod == 'gemma':\n",
    "            question_emb = json.dumps(get_gemma_embeddings(df.at[index, 'question']).tolist())\n",
    "            snippet_emb = json.dumps(get_gemma_embeddings(df.at[index, 'snippet']).tolist())\n",
    "            answer_emb = json.dumps(get_gemma_embeddings(df.at[index, 'answer']).tolist())\n",
    "            answerGenerated_emb = json.dumps(get_gemma_embeddings(df.at[index, 'answerGenerated']).tolist())\n",
    "            question_answerGenerated_falcon_emb = json.dumps(get_gemma_embeddings(df.at[index, 'question_answerGenerated_falcon']).tolist())\n",
    "            question_answerGenerated_llama_emb = json.dumps(get_gemma_embeddings(df.at[index, 'question_answerGenerated_llama']).tolist())\n",
    "            question_answerGenerated_mistral_emb = json.dumps(get_gemma_embeddings(df.at[index, 'question_answerGenerated_mistral']).tolist())\n",
    "            reverse_answer_answerGenerated_falcon_emb = json.dumps(get_gemma_embeddings(df.at[index, 'reverse_answer_answerGenerated_falcon']).tolist())\n",
    "            reverse_answer_answerGenerated_llama_emb = json.dumps(get_gemma_embeddings(df.at[index, 'reverse_answer_answerGenerated_llama']).tolist())\n",
    "            reverse_answer_answerGenerated_mistral_emb = json.dumps(get_gemma_embeddings(df.at[index, 'reverse_answer_answerGenerated_mistral']).tolist())\n",
    "            judge_answer_answerGenerated_falcon_emb = json.dumps(get_gemma_embeddings(df.at[index, 'judge_answer_answerGenerated_falcon']).tolist())\n",
    "            judge_answer_answerGenerated_llama_emb = json.dumps(get_gemma_embeddings(df.at[index, 'judge_answer_answerGenerated_llama']).tolist())\n",
    "            judge_answer_answerGenerated_mistral_emb = json.dumps(get_gemma_embeddings(df.at[index, 'judge_answer_answerGenerated_mistral']).tolist())            \n",
    "            df.at[index, 'question_emb'] = question_emb\n",
    "            df.at[index, 'snippet_emb'] = snippet_emb\n",
    "            df.at[index, 'answer_emb'] = answer_emb\n",
    "            df.at[index, 'answerGenerated_emb'] = answerGenerated_emb\n",
    "            df.at[index, 'question_answerGenerated_falcon_emb'] = question_answerGenerated_falcon_emb\n",
    "            df.at[index, 'question_answerGenerated_llama_emb'] = question_answerGenerated_llama_emb\n",
    "            df.at[index, 'question_answerGenerated_mistral_emb'] = question_answerGenerated_mistral_emb\n",
    "            df.at[index, 'reverse_answer_answerGenerated_llama_emb'] = reverse_answer_answerGenerated_llama_emb\n",
    "            df.at[index, 'reverse_answer_answerGenerated_falcon_emb'] = reverse_answer_answerGenerated_falcon_emb\n",
    "            df.at[index, 'reverse_answer_answerGenerated_mistral_emb'] = reverse_answer_answerGenerated_mistral_emb\n",
    "            df.at[index, 'judge_answer_answerGenerated_llama_emb'] = judge_answer_answerGenerated_llama_emb\n",
    "            df.at[index, 'judge_answer_answerGenerated_falcon_emb'] = judge_answer_answerGenerated_falcon_emb\n",
    "            df.at[index, 'judge_answer_answerGenerated_mistral_emb'] = judge_answer_answerGenerated_mistral_emb\n",
    "            df.at[index, 'gold_standard_cos'] = get_cosine_similarity(np.array(json.loads(answer_emb)), np.array(json.loads(answerGenerated_emb)))    \n",
    "            # Cosine\n",
    "            df.at[index, 'question_answerGenerated_falcon_cos']  = get_cosine_similarity(np.array(json.loads(question_emb)), np.array(json.loads(question_answerGenerated_falcon_emb)))\n",
    "            df.at[index, 'question_answerGenerated_llama_cos']  = get_cosine_similarity(np.array(json.loads(question_emb)), np.array(json.loads(question_answerGenerated_llama_emb)))\n",
    "            df.at[index, 'question_answerGenerated_mistral_cos']  = get_cosine_similarity(np.array(json.loads(question_emb)), np.array(json.loads(question_answerGenerated_mistral_emb)))\n",
    "            df.at[index, 'judge_answer_answerGenerated_falcon_cos']  = get_cosine_similarity(np.array(json.loads(answer_emb)), np.array(json.loads(judge_answer_answerGenerated_falcon_emb)))\n",
    "            df.at[index, 'judge_answer_answerGenerated_llama_cos']  = get_cosine_similarity(np.array(json.loads(answer_emb)), np.array(json.loads(judge_answer_answerGenerated_llama_emb)))\n",
    "            df.at[index, 'judge_answer_answerGenerated_mistral_cos']  = get_cosine_similarity(np.array(json.loads(answer_emb)), np.array(json.loads(judge_answer_answerGenerated_mistral_emb)))\n",
    "            df.at[index, 'ILRSim']  = np.mean([\n",
    "                df.at[index, 'question_answerGenerated_falcon_cos'],\n",
    "                df.at[index, 'question_answerGenerated_llama_cos'],\n",
    "                df.at[index, 'question_answerGenerated_mistral_cos']\n",
    "            ])\n",
    "            df.at[index, 'answer_judge_cos_mean']  = np.mean([\n",
    "                df.at[index, 'judge_answer_answerGenerated_falcon_cos'],\n",
    "                df.at[index, 'judge_answer_answerGenerated_llama_cos'],\n",
    "                df.at[index, 'judge_answer_answerGenerated_mistral_cos']\n",
    "            ])\n",
    "            df.at[index, 'question_snippet_similarity'] = get_cosine_similarity(np.array(json.loads(question_emb)), np.array(json.loads(snippet_emb)))\n",
    "            # Iaa\n",
    "            df.at[index, 'iaa_fleiss_kappa'], df.at[index, 'iaa_fleiss_kappa_agreement'], df.at[index, 'iaa_fleiss_kappa_disagreement'] = calculate_iaa_scores([\n",
    "                [round(df.at[index, 'question_answerGenerated_falcon_cos'], 2)],\n",
    "                [round(df.at[index, 'question_answerGenerated_llama_cos'], 2)],\n",
    "                [round(df.at[index, 'question_answerGenerated_mistral_cos'], 2)]\n",
    "            ], round(df.at[index, 'gold_standard_cos'], 2))\n",
    "            # Reconstruction error\n",
    "            df.at[index, 'question_reconstruction_falcon_error'] = np.mean((\n",
    "                np.array(json.loads(question_emb)) - np.array(json.loads(question_answerGenerated_falcon_emb))\n",
    "            ) ** 2)\n",
    "            df.at[index, 'question_reconstruction_llama_error'] = np.mean((\n",
    "                np.array(json.loads(question_emb)) - np.array(json.loads(question_answerGenerated_llama_emb))\n",
    "            ) ** 2)\n",
    "            df.at[index, 'question_reconstruction_mistral_error'] = np.mean((\n",
    "                np.array(json.loads(question_emb)) - np.array(json.loads(question_answerGenerated_mistral_emb))\n",
    "            ) ** 2)\n",
    "            df.at[index, 'ILRError']  = np.mean([\n",
    "                df.at[index, 'question_reconstruction_falcon_error'],\n",
    "                df.at[index, 'question_reconstruction_llama_error'],\n",
    "                df.at[index, 'question_reconstruction_mistral_error']\n",
    "            ])\n",
    "            # Case alignment\n",
    "            case_ = [np.array(json.loads(question_emb)), np.array(json.loads(answerGenerated_emb))]\n",
    "            case_base = [\n",
    "                [np.array(json.loads(question_answerGenerated_falcon_emb)), np.array(json.loads(reverse_answer_answerGenerated_falcon_emb))],\n",
    "                [np.array(json.loads(question_answerGenerated_llama_emb)), np.array(json.loads(reverse_answer_answerGenerated_llama_emb))],\n",
    "                [np.array(json.loads(question_answerGenerated_mistral_emb)), np.array(json.loads(reverse_answer_answerGenerated_mistral_emb))]\n",
    "            ]\n",
    "            df.at[index, 'ILRAlign'] = get_case_alignment(case_, case_base)\n",
    "            df.at[index, 'WILRAlign'] = get_weighted_case_alignment(case_, case_base)\n",
    "            df.at[index, 'question_alignment'] = get_question_alignment(case_, case_base)\n",
    "            df.at[index, 'question_bm25_score_mean'], df.at[index, 'question_rouge_score_mean'], df.at[index, 'question_bleu_score_mean'] = calculate_bm25_rouge_bleu(\n",
    "                df.at[index, 'question'], df.at[index, 'question_answerGenerated_llama'] , df.at[index, 'question_answerGenerated_falcon'], df.at[index, 'question_answerGenerated_mistral'])\n",
    "        if mod == 'mistral':\n",
    "            question_emb = json.dumps(get_mistral_embeddings(df.at[index, 'question']).tolist())\n",
    "            snippet_emb = json.dumps(get_mistral_embeddings(df.at[index, 'snippet']).tolist())\n",
    "            answer_emb = json.dumps(get_mistral_embeddings(df.at[index, 'answer']).tolist())\n",
    "            answerGenerated_emb = json.dumps(get_mistral_embeddings(df.at[index, 'answerGenerated']).tolist())\n",
    "            question_answerGenerated_llama_emb = json.dumps(get_mistral_embeddings(df.at[index, 'question_answerGenerated_llama']).tolist())\n",
    "            question_answerGenerated_gemma_emb = json.dumps(get_mistral_embeddings(df.at[index, 'question_answerGenerated_gemma']).tolist())\n",
    "            question_answerGenerated_falcon_emb = json.dumps(get_mistral_embeddings(df.at[index, 'question_answerGenerated_falcon']).tolist())\n",
    "            reverse_answer_answerGenerated_gemma_emb = json.dumps(get_mistral_embeddings(df.at[index, 'reverse_answer_answerGenerated_gemma']).tolist())\n",
    "            reverse_answer_answerGenerated_falcon_emb = json.dumps(get_mistral_embeddings(df.at[index, 'reverse_answer_answerGenerated_falcon']).tolist())\n",
    "            reverse_answer_answerGenerated_llama_emb = json.dumps(get_mistral_embeddings(df.at[index, 'reverse_answer_answerGenerated_llama']).tolist())\n",
    "            judge_answer_answerGenerated_gemma_emb = json.dumps(get_mistral_embeddings(df.at[index, 'judge_answer_answerGenerated_gemma']).tolist())\n",
    "            judge_answer_answerGenerated_falcon_emb = json.dumps(get_mistral_embeddings(df.at[index, 'judge_answer_answerGenerated_falcon']).tolist())\n",
    "            judge_answer_answerGenerated_llama_emb = json.dumps(get_mistral_embeddings(df.at[index, 'judge_answer_answerGenerated_llama']).tolist())            \n",
    "            df.at[index, 'gold_standard_cos'] = get_cosine_similarity(np.array(json.loads(answer_emb)), np.array(json.loads(answerGenerated_emb)))            \n",
    "            df.at[index, 'question_emb'] = question_emb\n",
    "            df.at[index, 'snippet_emb'] = snippet_emb\n",
    "            df.at[index, 'answer_emb'] = answer_emb\n",
    "            df.at[index, 'answerGenerated_emb'] = answerGenerated_emb\n",
    "            df.at[index, 'question_answerGenerated_falcon_emb'] = question_answerGenerated_falcon_emb\n",
    "            df.at[index, 'question_answerGenerated_gemma_emb'] = question_answerGenerated_gemma_emb\n",
    "            df.at[index, 'question_answerGenerated_llama_emb'] = question_answerGenerated_llama_emb\n",
    "            df.at[index, 'reverse_answer_answerGenerated_gemma_emb'] = reverse_answer_answerGenerated_gemma_emb\n",
    "            df.at[index, 'reverse_answer_answerGenerated_falcon_emb'] = reverse_answer_answerGenerated_falcon_emb\n",
    "            df.at[index, 'reverse_answer_answerGenerated_llama_emb'] = reverse_answer_answerGenerated_llama_emb \n",
    "            df.at[index, 'judge_answer_answerGenerated_gemma_emb'] = judge_answer_answerGenerated_gemma_emb\n",
    "            df.at[index, 'judge_answer_answerGenerated_falcon_emb'] = judge_answer_answerGenerated_falcon_emb\n",
    "            df.at[index, 'judge_answer_answerGenerated_llama_emb'] = judge_answer_answerGenerated_llama_emb            \n",
    "            # Cosine\n",
    "            df.at[index, 'question_answerGenerated_llama_cos']  = get_cosine_similarity(np.array(json.loads(question_emb)), np.array(json.loads(question_answerGenerated_llama_emb)))\n",
    "            df.at[index, 'question_answerGenerated_gemma_cos']  = get_cosine_similarity(np.array(json.loads(question_emb)), np.array(json.loads(question_answerGenerated_gemma_emb)))\n",
    "            df.at[index, 'question_answerGenerated_falcon_cos']  = get_cosine_similarity(np.array(json.loads(question_emb)), np.array(json.loads(question_answerGenerated_falcon_emb)))\n",
    "            df.at[index, 'judge_answer_answerGenerated_falcon_cos']  = get_cosine_similarity(np.array(json.loads(answer_emb)), np.array(json.loads(judge_answer_answerGenerated_falcon_emb)))\n",
    "            df.at[index, 'judge_answer_answerGenerated_gemma_cos']  = get_cosine_similarity(np.array(json.loads(answer_emb)), np.array(json.loads(judge_answer_answerGenerated_gemma_emb)))\n",
    "            df.at[index, 'judge_answer_answerGenerated_llama_cos']  = get_cosine_similarity(np.array(json.loads(answer_emb)), np.array(json.loads(judge_answer_answerGenerated_llama_emb)))\n",
    "            df.at[index, 'ILRSim']  = np.mean([\n",
    "                df.at[index, 'question_answerGenerated_llama_cos'],\n",
    "                df.at[index, 'question_answerGenerated_gemma_cos'],\n",
    "                df.at[index, 'question_answerGenerated_falcon_cos']\n",
    "            ])            \n",
    "            df.at[index, 'answer_judge_cos_mean']  = np.mean([\n",
    "                df.at[index, 'judge_answer_answerGenerated_llama_cos'],\n",
    "                df.at[index, 'judge_answer_answerGenerated_gemma_cos'],\n",
    "                df.at[index, 'judge_answer_answerGenerated_falcon_cos']\n",
    "            ])\n",
    "            df.at[index, 'question_snippet_similarity'] = get_cosine_similarity(np.array(json.loads(question_emb)), np.array(json.loads(snippet_emb)))\n",
    "            # Iaa\n",
    "            df.at[index, 'iaa_fleiss_kappa'], df.at[index, 'iaa_fleiss_kappa_agreement'], df.at[index, 'iaa_fleiss_kappa_disagreement'] = calculate_iaa_scores([\n",
    "                [round(df.at[index, 'question_answerGenerated_llama_cos'], 2)],\n",
    "                [round(df.at[index, 'question_answerGenerated_gemma_cos'], 2)],\n",
    "                [round(df.at[index, 'question_answerGenerated_falcon_cos'], 2)]\n",
    "            ], round(df.at[index, 'gold_standard_cos'], 2))\n",
    "            # Reconstruction error\n",
    "            df.at[index, 'question_reconstruction_llama_error'] = np.mean((\n",
    "                np.array(json.loads(question_emb)) - np.array(json.loads(question_answerGenerated_llama_emb))\n",
    "            ) ** 2)\n",
    "            df.at[index, 'question_reconstruction_gemma_error'] = np.mean((\n",
    "                np.array(json.loads(question_emb)) - np.array(json.loads(question_answerGenerated_gemma_emb))\n",
    "            ) ** 2)\n",
    "            df.at[index, 'question_reconstruction_falcon_error'] = np.mean((\n",
    "                np.array(json.loads(question_emb)) - np.array(json.loads(question_answerGenerated_falcon_emb))\n",
    "            ) ** 2)\n",
    "            df.at[index, 'ILRError']  = np.mean([\n",
    "                df.at[index, 'question_reconstruction_llama_error'],\n",
    "                df.at[index, 'question_reconstruction_gemma_error'],\n",
    "                df.at[index, 'question_reconstruction_falcon_error']\n",
    "            ])\n",
    "            # Case alignment\n",
    "            case_ = [np.array(json.loads(question_emb)), np.array(json.loads(answerGenerated_emb))]\n",
    "            case_base = [\n",
    "                [np.array(json.loads(question_answerGenerated_llama_emb)), np.array(json.loads(reverse_answer_answerGenerated_llama_emb))],\n",
    "                [np.array(json.loads(question_answerGenerated_gemma_emb)), np.array(json.loads(reverse_answer_answerGenerated_gemma_emb))],\n",
    "                [np.array(json.loads(question_answerGenerated_falcon_emb)), np.array(json.loads(reverse_answer_answerGenerated_falcon_emb))]\n",
    "            ]\n",
    "            df.at[index, 'ILRAlign'] = get_case_alignment(case_, case_base)\n",
    "            df.at[index, 'WILRAlign'] = get_weighted_case_alignment(case_, case_base)\n",
    "            df.at[index, 'question_alignment'] = get_question_alignment(case_, case_base)\n",
    "            df.at[index, 'question_bm25_score_mean'], df.at[index, 'question_rouge_score_mean'], df.at[index, 'question_bleu_score_mean'] = calculate_bm25_rouge_bleu(\n",
    "                df.at[index, 'question'], df.at[index, 'question_answerGenerated_gemma'] , df.at[index, 'question_answerGenerated_falcon'], df.at[index, 'question_answerGenerated_llama'])   \n",
    "\n",
    "    hf_dataset = DatasetDict({\n",
    "        'rawcases': Dataset.from_pandas(df)\n",
    "    })\n",
    "    hf_dataset.push_to_hub(\"Ramitha/alqa-results-40-\" + mod + \"-self\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
